\documentclass[czech,bachelor,dept420,male,cpdeclaration]{diploma}
% Dalsi doplnujici baliky maker
\usepackage{subfig}		% makra pro "podobrazky" a "podtabulky"
\usepackage{tikz}		% makra pro kresleni

%\usepackage[backend=biber]{biblatex}
\usepackage[backend=bibtex,style=numeric]{biblatex}

%\usepackage[czech]{babel}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{csquotes}

\usepackage{graphicx}
\usepackage[version-1-compatibility]{siunitx} %for units
\usepackage{amssymb}
\usepackage{caption} 
\usepackage{float}
\usepackage{subfig}
\usepackage{bm}
\usepackage{amsmath}
\usepackage{amsfonts}

%\usepackage{biblatex}
\addbibresource{myBib.bib}
\setlength\bibitemsep{1.7\itemsep plus 1pt minus 1pt}


\usepackage{listings}
\usepackage{color}
\definecolor{lightgray}{rgb}{.9,.9,.9}
\definecolor{darkgray}{rgb}{.4,.4,.4}
\definecolor{purple}{rgb}{0.65, 0.12, 0.82}

\lstdefinelanguage{JavaScript}{
  keywords={typeof, new, true, false, catch, function, return, null, catch, switch, var, if, in, while, do, else, case, break, let, const},
  keywordstyle=\color{blue}\bfseries,
  ndkeywords={class, export, boolean, throw, implements, import, this},
  ndkeywordstyle=\color{darkgray}\bfseries,
  identifierstyle=\color{black},
  sensitive=false,
  comment=[l]{//},
  morecomment=[s]{/*}{*/},
  commentstyle=\color{purple}\ttfamily,
  stringstyle=\color{red}\ttfamily,
  morestring=[b]',
  morestring=[b]"
}

\lstset{
   language=JavaScript,
   backgroundcolor=\color{white},
   extendedchars=true,
   basicstyle=\footnotesize\ttfamily,
   showstringspaces=false,
   showspaces=false,
   numbers=left,
   numberstyle=\footnotesize,
   numbersep=9pt,
   tabsize=2,
   breaklines=true,
   showtabs=false,
   captionpos=b
}

\colorlet{punct}{red!60!black}
\definecolor{background}{HTML}{EEEEEE}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}

\lstdefinelanguage{json}{
    basicstyle=\normalfont\ttfamily,
    numbers=left,
    numberstyle=\scriptsize,
    stepnumber=1,
    numbersep=8pt,
    showstringspaces=false,
    breaklines=true,
    frame=lines,
    backgroundcolor=\color{white},
    literate=
     *{0}{{{\color{numb}0}}}{1}
      {1}{{{\color{numb}1}}}{1}
      {2}{{{\color{numb}2}}}{1}
      {3}{{{\color{numb}3}}}{1}
      {4}{{{\color{numb}4}}}{1}
      {5}{{{\color{numb}5}}}{1}
      {6}{{{\color{numb}6}}}{1}
      {7}{{{\color{numb}7}}}{1}
      {8}{{{\color{numb}8}}}{1}
      {9}{{{\color{numb}9}}}{1}
      {:}{{{\color{punct}{:}}}}{1}
      {,}{{{\color{punct}{,}}}}{1}
      {\{}{{{\color{delim}{\{}}}}{1}
      {\}}{{{\color{delim}{\}}}}}{1}
      {[}{{{\color{delim}{[}}}}{1}
      {]}{{{\color{delim}{]}}}}{1},
}


\captionsetup[table]{skip=10pt}
%\sisetup{load-configurations = abbreviations}
%\sisetup{load-configurations = binary}
%\sisetup{per-mode=symbol,per-symbol = p}




\ThesisAuthor{Petr Vychodil}

\CzechThesisTitle{Vizuální nástroj pro zpracování LIDARových dat}

\EnglishThesisTitle{Visual Tool for LIDAR Data Processing}

\SubmissionDate{30. dubna 2019}

% Pokud nechceme nikomu dekovat makro zapoznamkujeme.
\Thanks{Chci poděkovat svému vedoucímu bakalářské práce Ing. Janu Gaurovi, Ph.D. za jeho vedení,
konzultace a odbornou pomoc. Dále bych chtěl poděkovat všem, kteří mi s prací pomohli, protože bez nich by tato práce nevznikla.}

% Zadame cestu a jmeno souboru ci nekolika souboru s digitalizovanou podobou zadani prace.
% Pokud toto makro zapoznamkujeme sazi se stranka s upozornenim.
\ThesisAssignmentImagePath{Figures/Zadani}

% Zadame soubor s digitalizovanou podobou prohlaseni autora zaverecne prace.
% Pokud toto makro zapoznamkujeme sazi se cisty text prohlaseni.
\AuthorDeclarationImageFile{Figures/Prohlaseni1.jpg}
\CooperatingPersonsDeclarationImageFile{Figures/Prohlaseni2.jpg}

%todo create abstract
\CzechAbstract{Tato bakalářská práce se zabývá implementací nástroje pro označování objektů a obrazových dat ve webovém prostředí. Označená data se stanou vstupem pro budoucí analýzu.}

\CzechKeywords{LIDAR, WebGL, bakalářská práce}

\EnglishAbstract{This bachelor thesis deals with implementation of tool for object selection and data visualization in web browser. Selected data will become input data for future analyzation.}

\EnglishKeywords{LIDAR, WebGL, bachelor thesis}

\AddAcronym{LIDAR}{Light Detection And Ranging}
\AddAcronym{WebGL}{Web Graphics Library}
\AddAcronym{OpenGL}{Open Graphics Library}
\AddAcronym{HTML}{Hypertext Markup Language}
\AddAcronym{NPM}{Node.js package manager}
\AddAcronym{XML}{Extensible Markup Language}
\AddAcronym{XHR}{XML Http Request}
\AddAcronym{HTTP}{Hypertext Transfer Protocol}
\AddAcronym{FOV}{Field Of View}
\AddAcronym{GPU}{Graphics processing unit}





\begin{document}
% Nechame vysazet titulni strany.
\MakeTitlePages

% Pokud mame v zaverecne praci vypisy kodu, jinak odstranit.
\lstlistoflistings

\section{Úvod}
Lidar funguje na stejném principu jako radar nebo sonar. Jen místo používání rádiových nebo zvukových vln používá světelné vlny. Využívá potenciál laseru na výpočet vzdálenosti od vzniku paprsku až po objekt, který je laserem zasažen. Objekt zasažen laserem odráží část paprsku laseru zpět ke zdroji. 

V dnešní době, kdy se fyzické výpočetní jednotky zmenšují a zároveň se zvětšuje výkon a jejich výpočetní síla, roste využití LIDARu hlavně v automobilovém odvětví. Dynamické mapování terénu může pomoci různými způsoby. Například reagovat na akce, na které by člověk nestihl svými smysly zareagovat. Tato technologie je klíčovou složkou v úplném nahrazení řízení auta člověkem. Pro představu výsledných dat modelu VLP-16 \ref{fig:lidarexample}. 


\begin{figure}[H]
\includegraphics[width=\linewidth]{Figures/lidar_preview.png}
\caption{Zobrazení dat z modelu VLP-16 pomocí softwaru VeloView. }
\label{fig:lidarexample}
\end{figure}

Cílem tohoto projektu je vytvořit nástroj ve webovém rozhraní, který bude sloužit pro označování objektů v LIDARových i obrazových datech. Tato data budou sloužit jako vstup pro budoucí analýzu dat. Projekt bude obsahovat i serverovou část pro implementaci přijímání a odesílání LIDARových dat a obrázků prostředí. Serverová část nejdříve pošle data, která ve webovém prostředí zobrazím. Na tomto prostředí bude naimplementované označování objektů, kde uživatel označí objekt, a pak všechna označená data posílám na serverovou část pro uložení. Na serverovou část se bude posílat i snímek bez LIDARových dat. Data na serveru budou použita pro následnou analýzu obrazu a vizualizační nástroj bude sloužit i k opětovnému přehrání označených dat. Snímek bude sloužit pro lepší představu o tom, o jaký objekt se jedná, protože u LIDARových dat to nemusí být vždy přesné. 
% zeptat se využití dat


\section{LIDAR}
V této kapitole vysvětlím princip fungování LIDARu, ukládání dat a přesněji představím použitý model. Také vysvětlím pojmy, které budu používat v dalších kapitolách.
\subsection{Princip fungování LIDARu}
V úvodu jsem Vám krátce představil, co je to LIDAR a jak fuguje. Nyní Vám ukážu fyzické fungování modelu VLP-16, se kterým jsem pracoval.  
Základní složkou, kterou LIDAR využívá a počítá s ní, je světlo a rychlost světla. LIDAR střílí světelné paprsky, které rychlostí světla letí k cíli. Část tohoto světelného paprsku se po nárazu s objektem odrazí, a putuje zpět stejnou rychlostí ke zdroji paprsku, kde paprsek zachytí senzor. Po dobu celého tohoto procesu je zaznamenáván čas, tzv. čas letu. Z těchto informací dostávám rovnici \eqref{eq:eq0}, která popisuje, jak LIDAR počítá vzdálenost bodu. Zkratka $s$ značí vzdálenost, $c$ rychlost světla a $t$ čas.

\begin{equation}
		s = \frac{\left ( c \cdot t \right)}{2} 
\label{eq:eq0}
\end{equation}

Pro představu, některá zařízení dokáží vystřelit až \num{150000} paprsků za sekundu. Vlnová délka se liší v závislosti na vzdálenosti a přesnosti. Pohybuje se v rozmezí 600-1000 \si{\nano\metre}. Čím nižší vlnová délka, tím je světlo méně pohlcováno vodou, ale za cenu vzdálenosti, na které je paprsek přesný. Z těchto poznatků je zřejmé, že stojí za to zvážit vlnovou délku v závislosti na využití. Každý paprsek má rozptyl \num{3} \si{\milli\radian}. Tímto rozptylem se zároveň snižuje přesnost bodu na větší vzdálenost.
Každý LIDAR má určitý počet kanálů, v rozmezí 8-128 kanálů laserových paprsků. S rostoucím počtem kanálů roste i rozlišení a větší přesnost mapovaného prostředí. Toto rozlišení je klíčová vlastnost, která je nezbytná v samořídících autech. Důvodem je víc informací o aktuálním prostředí, rychlejší a častější sběr informací. Samořídící auto, které je vybavené třicetidvou kanálovým LIDARem může jet bezpečně \num{56} \si{\km\per\hour}. Auto s 128-mi kanálovým LIDARem může jet rychlostí až \num{104} \si{\km\per\hour}. S rostoucí rychlostí potřebují mít senzory více kanálů.

\subsection{Model VLP-16}
Model VLP-16 byl využit při sběru dat pro mé účely. Zde je pár z jeho typických vlastností. Tento model má 16 kanálů. Sběr jedné kompletní odpalovací sekvence trvá \num{55,296} $\mu$s. Laser tohoto modelu pracuje na vlnové délce \num{905} \si{\nano\metre}. Mapa kanálů a úhlů, pod kterými operují paprsky laseru zmíněné v tabulce \ref{tab:tab1}. Díky nízké vlnové délce laseru má nízkou spotřebu energie. Funkční vzdálenost je až \num{100} metrů. LIDAR má horizontální zorné pole $360^ \circ$ a vertikální zorné pole $\pm 30^\circ$. Těmito vlastnostmi dokáže model získat dostatek kvalitních dat o objektech okolo sebe. Navíc váží pouze \num{830} gramů s velmi nízkou spotřebou elektrické energie. V tomto modelu je zaintegrován webový server pro jednoduchý monitoring a konfiguraci od výrobce. Tento model je specializován pro přenos dat po síti. Ethernetové připojení dokáže posílat data rychlostí až \SI{100}{MBps}. Je schopen ukládat záznamy paketů posílané přes ethernet. Jaká data a v jakém formátu jsou obsažena v jednotlivých UDP paketech Vám ukážu v kapitole \ref{secref:secref1}.


\subsection{Odpalovací sekvence}
Odpalovací sekvencí se označuje vždy čas, kdy byly vyslány paprsky laseru do všech možných úhlů v jednom azimutu. 
Jaké úhly a jaké množství paprsků přesně má LIDAR se liší model od modelu. Například model VLP-16 má 16 úhlů, do kterých se paprsky vysílají. 

\subsection{Režimy vrácení dat}\label{sec:sec2}
LIDAR je schopný pracovat ve dvou režimech. Nejdříve budu muset vysvětlit, jaká data LIDAR může vrátit. Při putování paprsku je možné, že paprsek světla narazí do prvního objektu, tomuto bodu dotyku budu říkat bod A. Tento objekt bude průhledný, a protože je průhledný, tak nepohltí a neodrazí celý paprsek zpět. Z prvního střetu je část paprsku odražena zpět k LIDARu. Paprsek po průchodu prvním objektem pokračuje dál a narazí na jiný objekt, například zeď. Místu střetu se zdí budu říkat bod B. Po tomto střetu se zbytek světelného paprsku odrazí zpět k senzoru. Nyní mám bod A a bod B, které LIDAR zaznamenal. Záleží na nastavení režimu, který rozhodne, zda uloží oba body nebo jen jeden. Bod A se vrátí k senzoru jako první. Díky průhlednosti materiálu se část paprsku vrátí a část projde dál. Bod, který LIDAR zaznamenal se vrátí jako nejsilnější vrácený bod, v angličtině nazvaný jako \uv{strongest return}. Zbytek paprsku, který se odrazil od zdi, v mém případě bod B, je nazýván poslední vrácený bod, v původním znění jako \uv{last return}. Toto jsou dva typy bodů, které je LIDAR schopen vrátit.  

	\begin{itemize}
		\item Návrat dvou (Dual return)
		\item Návrat jednoho (Single return)
	\end{itemize}
	
Režim vrácení dat si uživatel může při konfiguraci LIDARu nastavit. Režim návrat dvou zařizuje vrácení nejsilnějšího i posledního vráceného bodu. Tato konfigurace zaručí přesnější obraz prostředí. Na druhou stranu se pro jeden kompletní obraz posílají \num{2} rámce s daty.  Tímto je zapříčiněno, že doba celkového obrazu se zdvojnásobí. Tento režim se používá převážně k mapování terénů. Zaznamená vegetaci (druhý nejsilnější bod) a samotný terén (nejsilnější bod).

Návrat jednoho, jak už název vypovídá, ukládá pouze jeden druh vrácených dat. Uživatel si při konfiguraci LIDARu může vybrat, jestli ho zajímá poslední vrácený nebo nejsilnější vrácený bod. Tento režim je dvojnásobně rychlejší, než režim návratu dvou a používá se v automobilovém průmyslu, kdy je potřeba rychlost. Proto se většinou nastavuje tento režim s nastavením vrať nejsilnějšího. Nejčastěji je potřeba vrátit pevný objekt, aby systém mohl nasimulovat překážky, na které během provozu může narazit. Pevný objekt bývá v převážné většině nejsilnější vrácený bod. 

\subsection{Vertikální úhly a kanály}
V této části budu tyto úhly ukazovat na modelu VLP-16, ale princip zůstane stejný. Jediný rozdíl bude v počtu laserů a velikosti úhlů. Model VLP-16 má šestnáct kanálů, kde každý kanál má svůj vlastní paprsek laseru. Každý paprsek v laseru má svůj vlastní úhel. Data uložená v datovém bloku jsou indexována podle čísel kanálů.


\begin{table}[!htbp]
\centering
\caption{Mapa kanálů modelu VLP-16 i s vertikálními úhly.}
\label{tab:tab1}
\begin{tabular}{|c|r|}
\hline
Kanály & Vertikální úhly	\\
\hline
0 &   $-15^\circ$   \\
1 &   $1^\circ$	  \\
2 &   $-13^\circ$  \\
3 &   $-3^\circ$   \\
4 &   $-11^\circ$  \\
5 &   $5^\circ$    \\
6 &   $-9^\circ$   \\
7 &   $7^\circ$    \\
8 &   $-7^\circ$   \\
9 &   $9^\circ$    \\
10 &  $-5^\circ$  \\
11 &  $11^\circ$  \\
12 &  $-3^\circ$  \\
13 &  $13^\circ$  \\
14 &  $-1^\circ$  \\
15 &  $15^\circ$  \\
\hline
\end{tabular}
\end{table}

Vertikální úhly jsou určeny vzhledem k pomyslné vodorovné ploše, procházející středem LIDARového senzoru. Každý vrácený bod v datovém bloku je uložen pod číslem kanálu. 
 
\subsection{Mrak bodů}
V angličtině známý jako \uv{Point cloud}. Jak název již napovídá, je to množina bodů v prostoru. Mrak bodů bývá vytvořen 3D skenery jako je LIDAR. Tento pojem se používá při vizualizaci těchto dat, protože když zobrazím výsledek, tak vzhledem připomíná oblak bodů. Tato práce je o vizualizaci těchto bodů v libovolném webovém frameworku a následné selekci.


\subsection{Výstupní data}\label{secref:secref1}
Každý model ukládá data v různých formátech. Data jsou uložená v paketu, který je složen z jednoho až n datových bloků. Každý z těchto datových bloků je složen z jedné až n dat z odpalovacích sekvencí, které jsou uložené pod číslem kanálu. Tato část bude specifičtěji zaměřená na model VLP-16. Celý paket má velikost \num{1248} bytů. Těchto \num{1248} bytů je rozděleno do hlavičky paketu, datových bloků, timestampu a factory. Hlavička paketu má velikost \num{42} bytů, je důležitá pro internetovou komunikaci pomocí TCP/IP protokolu. Následuje \num{12} datových bloků. Každý z těchto datových bloků má velikost \num{100} bytů. Skládá se z označujících dvou bytů, které označují začátek nového datového bloku, dvou bytů velikosti azimutu a z \num{96} bytů čistých dat. Tyto data mají v sobě dvě odpalovací frekvence, kde jedna odpalovací frekvence má \num{16} kanálů. Dohromady je \num{32} kanálů, kde každý kanál se skládá ze \num{2} bytů vzdálenosti a jednoho bytu reflektivity. Celkem to bude 32(2+1), to je \num{96} bytů plus \num{4} byty. Dohromady je \num{100} bytů, které dávají jeden kompletní datový blok. Azimut, označený na začátku datového bloku, je pouze pro první odpalovací frekvenci. Azimut pro druhou odpalovací frekvenci není explicitně napsán v datovém bloku, ale může být vypočten přičtením jedničky. Stále zbývá posledních 6 bytů do \num{1248} bytů. V prvních \num{4} bytech je uložené časové razítko, které je synchronizováno s GPS systémem. A v posledních dvou bytech je uložené tovární nastavení. V prvním z těchto bytů je uložen režim vrácení dat, již zmíněno v kapitole \ref{sec:sec2}, a v posledním je uloženo označení modelu. Hodnoty a význam těchto bytů ukážu na obrázku \ref{fig:packet}.

\begin{figure}[H]
\includegraphics[width=\linewidth]{Figures/packet.png}
\caption{ Paket modelu VLP-16 \cite{packet}. }
\label{fig:packet}
\end{figure}

Značka \texttt{xFFEE} na začátku každého datového bloku značí zahájení nového datového bloku. Tato hodnota je určená výrobcem a je neměnná. \texttt{Factory}, tovární nastavení na konci paketu, s hodnotou \num{37} hexadecimálně označuje, že LIDAR je nastaven v režimu vrácení jednoho s nastavením vrať nejsilnější bod. Hodnota \num{38} hexadecimálně označuje také režim vrácení jednoho, ale vrací poslední vrácený bod. Poslední možnost s hodnotou \num{39} hexadecimálně znamená režim vrácení dvou. Poslední byte označuje model, ze kterého je tento paket.

Obsah paketu se liší v závislosti na režimu vrácení dat. Při režimu vrácení dvou se posílají stejné pakety s rozdílem, že se posílají párové datové bloky. Párovým blokem jsou myšleny dva datové bloky paketu, které obsahují odpalovací sekvence se stejným azimutem. Na obrázku \ref{fig:packet2} jsou vidět dva databloky. Každý z nich obsahuje dvě odpalovací sekvence. Tyto dva databloky mají stejný azimut. První i druhý datablok obsahují stejný azimut odpalovacích sekvencí, ale liší se typem vrácených dat. První z páru vždy obsahuje hodnotu posledního vráceného bodu, druhý datový blok obsahuje hodnotu nejsilnějšího vráceného bodu. 
 
\begin{figure}[H]
\includegraphics[width=\linewidth]{Figures/paket-dual.png}
\caption{ Paket modelu VLP-16 v režimu vrácení dvou \cite{packet}. }
\label{fig:packet2}
\end{figure}

\subsection{Předzpracování dat}\label{secref:predzpracref1}
Předzpracování dat závisí na tom, zda chci provádět přenos dat v reálném čase ke zpracování, nebo ukládat pakety dat do souborů s příponou \texttt{.pcap}. Přenos dat v reálném čase se využívá v autonomních automobilech, kde automobil musí reagovat na překážky. Já nebudu potřebovat komunikaci a vizualizaci v reálném čase. Účel budovaného systému bude hlavně k vizualizaci LIDARových dat a následnému označování určitých částí mraku bodů, který bude vracet na serverovou část k uložení snímku vybrané části i všech LIDARových bodů z označené oblasti. 
Data proto nezískávám z aktivní komunikace LIDARu se zařízením, ale z \texttt{pcap} souborů vytvořených LIDARem. \texttt{Pcap} soubor je záznam komunikace přes TCP/IP protokol. Tento soubor je složen z mnoha paketů \ref{secref:secref1}. K vizualizaci dat z \texttt{pcap} souboru je nutné nejdříve extrahovat informace, které jsou uvnitř jednotlivých paketů. Data jsem se rozhodl transformovat rovnou do kartézských souřadnic, abych předešel zbytečným a velmi komplikovaným výpočtům na straně uživatele. K tomuto účelu jsem použil Python konzoli v programu VeloView. Hlavním důvodem využití této konzole bylo přístupné Python rozhraní pro práci s \texttt{pcap} soubory. Zmíněné rozhraní používá knihovnu napsanou v jazyce C++, aby zpracování bylo co nejrychlejší. Tato knihovna je specificky napsána pro práci s LIDARem a \texttt{pcap} soubory, proto jsem vytvořil jednoduchý script v jazyce Python, který využívá již zmíněné rozhraní a přetransformuje \texttt{pcap} soubor na neznámý počet JSON souborů. Každý JSON soubor obsahuje jeden kompletní mrak bodů.

\lstinputlisting[language=python,caption=Python script pro transformaci \texttt{pcap} souborů na JSON soubory.]{SourceCodes/transformdata.py}

Tento script spouštím v Python konzoli programu VeloView po načtení \texttt{pcap} souboru. Příkaz \texttt{vv.gotoNext()} nás přesune na další ze zmapovaných mraků bodů. V proměnné \texttt{cloudinfo} máme uložený aktuální snímek mraku bodů, který má uživatel zobrazen a všechna možná dostupná data, která byla v paketech uložena i s metadaty. Proměnná \texttt{points} vrátí pole všech bodů aktuálního mraku bodů. Každý tento vrácený bod obsahuje trojici čísel, která odpovídá kartézským souřadnicím v prostoru. Proměnná \texttt{data} je slovník, do kterého v cyklu ukládám potřebná data. Slovník je specifický tím, že se do něj ukládá klíč a na daný klíč je navázaná hodnota, v mém případě klíč je číslo bodu a k tomu navazující hodnota z proměnné \texttt{points} na indexu klíče. Po ukončení všech iterací cyklu vytvořím soubor a pomocí externí knihovny \texttt{json}, kterou jsem na začátku scriptu importoval, vytvořím ze slovníku JSON řetězec a uložím ho do souboru. Každý soubor začíná prefixem \texttt{LidarData\_X}, kde X je index aktuálního mraku bodů. Po spuštění tohoto scriptu mám všechna data, která potřebuji na vizualizaci mraku bodů a následnou práce s ním. Data následně uložím do databázového systému. 




\section{Vizualizace}
Tato část je určena vizualizaci. V této kapitole Vám ukážu, jak jsem postupoval při vývoji systému. Od procesu výběru technologií a frameworků až po principy vykreslování. Ze zadání je zřejmé, že vizualizace dat musí probíhat v prohlížeči na straně uživatele a musí být zobrazená ve 3D. V serverové části budu mít možnost si uložit vybraná data, popřípadě obrázky.

\subsection{Výběr technologií} 
Na straně uživatele používám programovací jazyk JavaScript. K těmto účelům bylo vytvořené JavaScriptové rozhraní pro použití WebGL, které využívá rozhraní OpenGL. OpenGL je abstraktní rozhraní pro práci s grafikou. Implementace OpenGL jsou vytvořeny pro všechny platformy a naprogramovány na rychlejších jazycích, pracují přímo s grafickou kartou pro vysokou výpočetní rychlost. Knihovna, kterou jsem si vybral je Three.js. Three.js je knihovna, která detekuje verzi prohlížeče a použije nejnovější technologie a nejnovější implementace JavaScriptu, které jsou prohlížečem možné použít. Hlavními důvody, proč jsem použil tuto 3D knihovnu, byla její rozsáhlá a detailně zpracovaná dokumentace. 
V serverové části jsem se rozhodl použít programovací jazyk Java. Bude mít za úkol posílat mraky bodů na stranu uživatele a zpracovat, nebo uložit data odeslaná uživatelem. Pro vytvoření webové aplikace jsem využil knihovnu Spring Boot. Dalším rozšířením je knihovna Thymeleaf pro dynamické renderování HTML na straně serveru. Již zmíněné technologie jsou nedílnou součástí praktické části. Jako bundler statických prvků a minifikaci JavaScriptu jsem použil nástroj zvaný Webpack. Jeho výhodou je jednoduchá konfigurace a používání. Bundler spojí všechny potřebné použité javascript soubory do jednoho zminifikovaného souboru. Pro ukládání dat použiji objektově-relační databázový server PostgresSQL, který je zdarma a je připravený na vysoký počet požadavků.
 
\subsection{Alternativní knihovny} 
Je mnoho alternativních knihoven, které jsem mohl použít. Ukáži Vám pár z nich. Za zmínku stojí Babylon.js. Tato knihovna se používá na vytváření her v prohlížeči. Kód z Babylon.js je možné exportovat do Unity 3D herního enginu. Zaměřuje se tedy více na kolize, události, rendering a vyhlazování. Oba dva jsou v tuto chvíli nejlepšími 3D JavaScriptovými knihovnami s open source licencí. Alternativou Webpack bundleru je Rollup. Konfigurací se velmi podobá Webpack bundleru. Je jen o zanedbatelnou dobu pomalejší. Na straně serveru jsem mohl použít mnoho různých alternativ, protože požadavek od serveru je odpovídat a přijímat žádosti o data a posílat je uživateli na jeho rozhraní, přijímat označená data z uživatelského rozhraní a ukládat je na straně serveru k budoucí analýze. Další možností byla webová aplikační knihovna Django s programovacím jazykem Python. Tato kombinace je velmi dobrá pro rychlý vývoj jednoduchých aplikací. Další alternativou bylo PHP s některým z frameworků, jako je například Laravel. Neměl jsem žádné specifické požadavky od systému, ve kterých bych mohl říct, že využiji určitý programovací jazyk, protože by byl pro tuto problematiku lepší. Požadavky od serverové části by efektivně zvládlo mnoho jazyků. Nelze tedy z požadavků vybrat jen jeden jazyk a říct, že bude pro tento účel nejlepší. Pro databázový server jsem měl mnoho možností. Jedním z mnoha je MySQL. Tento databázový server je velmi rychlý i ve velkém množství čtecích operací. Je také úspornější na místo v paměti, ale za cenu problému s konkurencí. Pro náš systém jsem potřeboval databázový systém, který bude efektivně číst a psát větší množství dat.


\subsection{Základy knihovny Three.js}
Abych mohl pomocí knihovny Three.js cokoliv zobrazit, tak k tomu potřebuji tři nezbytné a základní věci, bez kterých bych se neobešel. Těmito třemi základními věcmi jsou scéna, kamera a renderer. Scéna je virtuální trojrozměrný prostor, do kterého přidávám objekty. Kamera zařizuje projekci objektů na 2D obrazovku, jaký typ projekce záleží na kameře. Poslední a nejdůležitější částí je renderer. Renderer zařizuje vykreslení scény z pohledu kamery, popřípadě více kamer. Stále mi tyto prvky nemají co zobrazit, nejdříve si musím vytvořit nějaké objekty, které mohu přidat do scény. Každý objekt musí mít pozici, na kterou ji přidáváme do scény. Scéna v Three.js má souřadnicový systém pravotočivý. Když si vezmu pravou ruku a dám ji dlaní před sebe, tak osu \texttt{x} představuje palec, ukazováček směřující vzhůru je osa \texttt{y} a pokrčený  prostředníček směřující k tělu je osa \texttt{z}.


\subsection{Vytváření objektů v Three.js}\label{secref:secref6}
K vytvoření každého objektu potřebuji množinu vrcholů, stěn a materiálů ve WebGL. Three.js má již jednoduché rozhraní, které mi dovoluje vytvářet různé objekty, bez znalostí knihovny WebGL. Knihovná má již vyřešené vytváření základních 3D geometrických objektů, jako je krychle, koule, křivky a mnoho dalších. Zde je ukázka vytvoření koule o poloměru \num{0,005}. 

\lstinputlisting[language=JavaScript,caption=Vytvoření koule za pomoci knihovny Three.js]{SourceCodes/threeJSSphere.js}

První potřebuji vrcholy a stěny. O to se postará \texttt{THREE.SphereGeometry}, který jako první parametr bere průměr koule, druhý parametr je počet segmentů na šířku a třetí počet segmentů na výšku. Čím více segmentů daná koule má, tím je přesnější a kulatější. Rozdíly jsou vidět na obrázku \ref{fig:spheres}. Počty segmentů jsou shora i zdola omezeny. Maximum je \num{32} u výšky i šířky a minimum se liší. U výšky je minimum \num{2}, a u šířky \num{3}.

\begin{figure}[H]
    \centering
    \subfloat[Pět segmentů na výšku i šířku]{{\includegraphics[width=5cm]{Figures/sphere1.png} }}
    \qquad
    \subfloat[Třicetdva segmentů na výšku i šířku]{{\includegraphics[width=5cm]{Figures/sphere2.png} }}
    \caption{Rozdíly v počtu segmentů}
    \label{fig:spheres}
\end{figure}

S narůstajícím počtem segmentů jsou nároky na GPU vyšší, protože musí vykreslit více vrcholů a hran koule. Proto jsem v projektu použil malý počet segmentů na výšku i šířku koulí \num{5}. Když vezmu v potaz, že každé vykreslení mraku bodů má \num{25000} takových koulí, tak budu chtít nároky na GPU co nejnižší.
Dále potřebuji ještě materiál, který mi vyplní všechny stěny a vrcholy. Je hodně různých druhů materiálů. Každý materiál má své specifické vlastnosti, jak se zobrazuje ve světle. Tato vlastnost \texttt{THREE.MeshLambertMaterial} v kombinaci se světlem pomůže rozlišit jednotlivé koule (LIDARové body) od sebe. Kdybych použil materiál \texttt{THREE.Basic}, tak bych nerozeznal jednu kouli od druhé. Na tento materiál nepůsobí světlo, proto ať už bych se podíval na jakoukoliv část koule, tak by měla konstantní odstín barvy materiálu. Koule by splývaly mezi sebou. Při vytváření nové instance materiálu musím přidat barvu do konstruktoru. \texttt{THREE.Mesh} si jako argument požaduje geometrii a materiál, který má vyplnit stěny dané geometrie. Mesh vytvoří výsledný objekt, v mém případě kouli. Tento objekt je možné vložit přímo do scény pro zobrazení koncovému uživateli.

\subsection{Alternativní řešení}
Jedno z dalších možných řešení je program VeloView. Program VeloView je aplikace na stolní počítač, který slouží pouze k vizualizaci LIDARových dat z LIDARů od firmy Velodyne. Firma Velodyne se specializuje převážně na zlepšení a zdokonalení LIDARů zaměřených na automobilovou část průmyslu. Veloview, narozdíl od mého vytvářeného systému, není ve webovém rozhraní dostupný odkudkoliv a z jakéhokoliv systému. Dalším rozdílem je, že zobrazuje čistě LIDARová data a nedovoluje přidat pozadí, abych si mohl i graficky představit prostředí, v jakém se auto pohybuje. Označování objektů a následný export dat je v obou již zmiňovaných LIDARových nástrojích.
Další alternativou je Python knihovna s názvem Point Processing Toolkit, ve zkratce PPTK. Tato knihovna dokáže vizualizovat body v dvojrozměrném, ale i v trojrozměrném prostoru. Dále podporuje selekci bodů v prostoru přes uživatelské rozhraní, stejně jako program VeloView. Avšak narozdíl od programu VeloView, PPTK data pouze vizualizuje, proto potřebuje data určující pozici v prostoru. VeloView používá data přímo z výstupních souborů, které generuje LIDAR. Stejně jako VeloView je možné tento program použít pouze na počítačích a bez možného přidání snímku do pozadí projekce.


\subsection{Princip fungování kamery}\label{secref:secref16}
Kamera vytváří perspektivní projekci na scénu. Než vysvětlím, jak funguje perspektivní projekce, nejdříve musím objasnit, na jakém principu pracuje kamera. Perspektivní kamera zachycuje scénu pohledem oka. Zóna zachycení kamery je specifikována jako frustum. Frustum je složeno z šesti rovin, které dělí prostor. Uvnitř frustumu je zachycena část scény, kterou chci kamerou zobrazit. Frustum se skládá z šesti rovin: horní, spodní, nalevo, napravo a dvě roviny vpřed a v dálce. Úhlu mezi horní a dolní rovinou se říká horizontální field of view, zkráceně FOV. Tento úhel bývá v rozmezí $30^\circ-60^\circ$. Přední rovina ohraničená dalšími rovinami je obrazovka, do této roviny se provede projekce všeho, co je uvnitř frustumu. 

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{Figures/perspectiveProjection.png}
\caption{Perspektivní projekce kamery \cite{learnwebgl}. }
\label{fig:perspectiveProjection}
\end{figure} 

Jak je vidět na obrázku, když chci promítnout bod na přední rovinu (obrazovka), tak vektor ze středu kamery k vrcholu objektu musí protnout přední rovinu. Bod střetu tohoto vektoru s rovinou je perspektivní projekce tohoto bodu na naši obrazovku. Takto je to provedeno se všemi hranami a vrcholy všech objektů. Tímto promítnutím na plátno zůstává zachovaný poměr $\frac{y'}{z'}=\frac{y}{z}$. 


Pro zjišťování obrysů ve scéně za kurzorem budu používat Ray-tracing algoritmus. Ray-tracing, jak už z názvu vyplývá, bude sledovat paprsek, který vychází ze středu kamery přes promítací rovinu a zachytí všechny stěny geometrie po jeho trase. Při získání geometrie, kterou protnul, si zjistí, o jaký objekt se jedná. Ukáži to na obrázku \ref{fig:perspectiveProjection}. Paprsek vznikne ve středu kamery a protíná určité místo promítací roviny. Tímto se snažím najít jakýkoliv objekt, který za tímto místem je. Používám implementaci tohoto algoritmu ve třídě \texttt{Raycaster}.


\section{Implementace}
V této kapitole ukáži postup a implementaci systému od úplného začátku až do konce. Začnu na serveru od základní funkcionality až po datový model, pak se přesunu k vizualizaci a selekci i s odesíláním dat na straně uživatele.


\subsection{REST API} 
REST API je rozhraní na straně serveru, které za pomoci HTTP požadavků provádí akce s daty. Cílem je vytvořit akce na url adresy pro získání/uložení LIDARových dat. Akce musí být parametrizovatelné, aby server věděl, jaká data má uživateli poskytnout, popřípadě uložit. Nejdříve potřebuji mít nějaká lidarová data a snímky z přední a zadní strany jízdy. Tato data musí být uložená na serveru, přesněji v databázi, abych je mohl poskytovat uživateli. Dále si uživatel bude moci vybírat určité části lidarového mraku bodů s obrazovými daty, a proto je budu muset uložit. Dále ještě musím poskytnout již zmíněné selekce k znovuzobrazení. Tyto služby budu pomocí \texttt{REST API} poskytovat, aby mohla aplikace na straně uživatele komunikovat se serverem.


\subsection{Datový model} 
Důležitou částí je datový model mého informačního systému. Model si rozdělím podle požadovaných požadavků od serveru, ukládání selekcí objektů a získávání všech možných dat z jednoho mraku bodů. Na obrázku \ref{fig:datamodel} je vidět rozdělení těchto požadavků zobrazených UML diagramem. Tabulka \texttt{main\_menu\_storage} obsahuje všechny unikátní výjezdy s LIDAR zařízením. Každý mrak bodů je uložen na samostatném řádku, tabulka \texttt{raw\_data\_store}, s přímým odkazem na to, v jaké jízdě byl zaznamenán a odkazem na další tabulku \texttt{raw\_data\_pictures}. V této tabulce jsou uloženy odkazy ke snímkům na disku z přední a zadní strany vozidla. Tyto zmíněné tabulky jsou potřebné k posílání dat na stranu uživatele za účelem vizualizace. Druhou částí je ukládání selekce specifických objektů, které si uživatel vybral. V tabulce \texttt{selected\_data\_parts} jsou uloženy všechny body dané selekce s informací, ze kterého mraku bodů byla vytvořena. Jsou zde uloženy ještě další informace. Mezi tyto informace patří jméno objektu v selekci, tabulka \texttt{selected\_item\_name} a snímek selekce, tabulka \texttt{selected\_item\_pictures}.

%todo change picture to some vector

\begin{figure}[H]
\includegraphics[width=\linewidth]{Figures/dataModel.png}
\caption{Datový model informačního systému. }
\label{fig:datamodel}
\end{figure} 



\subsection{Scéna a kamera} 
Scéna je virtuální prostor, do kterého budu přidávat LIDARové body. K požadovanému zobrazení této scény potřebuji ještě kameru a renderer. Kamera ohraničuje specifickou část prostoru, kterou renderer zobrazí. Tato část prostoru se nazývá kamerové frustum. Renderer zajistí, aby se pracovalo pouze s objekty, které leží uvnitř tohoto frustumu. Kamera zajistí projekci viz. \ref{secref:secref16}. 

\begin{minipage}{\linewidth} 
\lstinputlisting[language=JavaScript,label={secref:secref17},caption=Vytvoření scény s kamerou a rendererem.]{SourceCodes/mainScene.js} 
\end{minipage} 

V kódu \ref{secref:secref17} je vidět konstruktor a metody \texttt{animate}, \texttt{stopAnimation} a \texttt{onWindowResize}. V konstruktoru vytvářím virtuální scénu, perspektivní kameru a renderer. Vytvoření je velmi snadné s Three.js knihovnou. Pro projekt jsem vybral perspektivní kameru, abych napodobil pohled lidského oka, který zkresluje velikost objektu s rostoucí vzdáleností. Tímto se liší ortografická kamera od perspektivní. K vytvoření kamery potřebuji nejdříve pár důležitých parametrů. Prvním parametrem je \texttt{field of view}, neboli zorné pole. Tímto číslem určím úhel ve stupních, který bude mít vertikální úhel kamerového frustumu. Vertikální FOV u běžných kamer jsou v rozmezí $60\circ$ - $110\circ$. Druhým parametrem je poměr stran rámce, do kterého budu chtít zobrazit naši scénu. V mém případě chci výsledný rámec přes celou obrazovku prohlížeče, proto \texttt{window.innerWidth / window.innerHeight}. Na základě tohoto parametru si Three.js dopočítá horizontální FOV, aby obraz nebyl zkreslený. Třetí parametr značí vzdálenost od pozice kamery k přední stěně pyramidového frustumu. V této vzdálenosti vznikne promítací rovina, na kterou se uživateli promítne scéna a vytvoří obraz do rámce v prohlížeči. Poslední parametr značí také vzdálenost, ale k nejvzdálenější stěně kamerového frustumu. Renderer zajistí vytvoření výsledného HTML canvas plátna, proto je nutné určit mu velikost tohoto plátna. Poté přidám do objektového modelu dokumentu stránky. To ještě není všechno, stále potřebuji funkci, která bude periodicky vykreslovat aktuální scénu na plátno. K tomuto účelu použiji metodu \texttt{animate}, která využívá funkci \texttt{requestAnimationFrame}. Tato funkce říká prohlížeči, že chci provést animaci a specifikovat chování překreslení. Proto do této funkce dávám jako parametr referenci na funkci \texttt{animate}. Tímto vytvořím nekonečný cyklus, kde v každé iteraci budu na rendereru volat metodu \texttt{render}. Ve zmíněném kódu ještě mám vytvořený posluchač na událost změna velikosti, který upraví poměr stran kamery a aktualizuje její projekční matici. Dále už jen aktualizuje velikost výsledného plátna. Výsledkem tohoto kódu je plátno v HTML stránce s pohledem na scénu. Bohužel nic na plátně není vidět, protože žádný objekt není ve scéně.



\subsection{Vizualizace LIDARových dat}  
Zakladem informačního systému je uživateli vizualizovat mrak bodů z LIDARového zařízení. K tomuto účelu nejdříve potřebuji získat data ze serveru. Uživatel musí specifikovat, jaká data chce získat, který mrak bodů, a z jaké jízdy. Musím tedy vytvořit uživateli posuvník, kterým se bude orientovat mezi snímky mraku bodů. Tento posuvník bude nabývat hodnot 
$\langle \texttt{0, m}\rangle \subset \mathbb{N}$, kde $m$ je maximální počet uložených mraků bodů pro danou jízdu. Pro získání dat mraku bodů si musím vytvořit požadavek na server. Server prostřednictvím REST-API poskytne objekt, který obsahuje $l$ objektů, kde $l$ je množství lidarových bodů v našem mraku. Každý z těchto objektů obsahuje pole s pozicemi v kartézské soustavě souřadnic. Jak jsem získal takto předzpracovaná data najdete v kapitole \ref{secref:predzpracref1}. Pro získání dat použiji kód \ref{secref:loaddataref1}.

\lstinputlisting[language=JavaScript,label={secref:loaddataref1},caption=Metoda pro získání LIDARových dat ze serveru.]{SourceCodes/loadDataFromServerAndRenderPoints.js}

Nejdříve si uložím referenci kontextu do proměnné \texttt{that}, protože později budu mít kontext \texttt{this} jiný a nedokázal bych získat instanční proměnné z naší třídy. Dále specifikuji, jaký požadavek a na jakou url adresu chci požadavek posílat. Jak můžete vidět, vkládám do url proměnné z aktuálního kontextu. Budu totiž chtít specifikovat, z jaké jízdy brát mraky bodů a zároveň číslo mraku bodů, který uživatel chce vidět. Číslo mraku bodů bude získáno na základě posuvníku. Při zaslání požadavku nikdy přesně nevíme, kdy server odpoví a kdy dorazí data, kterých jsme se dotazovali. K tomu mi pomůže funkce \texttt{onreadystatechange}. Ta se spustí vždy, když se změní stav požadavku. Vytvořím si uvnitř této metody akce, které budu chtít provést jen když je komunikace ukončena a konečný status požadavku je 200 OK. Nasledně jen zpracuji tělo požadavku z JSON formátu do JavaScript objektu a přejdu k vykreslení mraku bodů.


\lstinputlisting[language=JavaScript,caption=Metoda pro vykreslení LIDARových dat.]{SourceCodes/renderPointsFromData.js}

\texttt{Three.js} umožňuje vytvářet skupiny objektů, které slouží k lepší přehlednosti v kódu. Skupina \texttt{groupOfPoints}, je již přiřazená do scény. Kdykoliv přidám do této skupiny objekt, automaticky se vloží i do naší virtuální scény. K vytvoření meshe potřebuji dvě věci, geometrii a materiál \ref{secref:secref6}. Protože budu přepoužívat geometrii a materiál, tak si je uložím do proměnných ještě před kompletními iteracemi lidarových bodů. V proměnné \texttt{thatPoints} jsou data ze serveru. Pak už jen vytvořím cyklus, který v každé iteraci vytvoří nový mesh objekt a nastaví mu pozici ve scéně.

\begin{figure}[H]
\includegraphics[width=\linewidth]{Figures/sceneWithPoints.png}
\caption{Výsledná vizualizace.}
\label{fig:sceneWithPoints}
\end{figure}
	 

\subsection{Výběr prostoru}\label{secref:secref10}
K označení určité části v prostoru musím vzít v potaz, že na obrazovce mám projekci z kamery \ref{secref:secref16}. Tohle je důležité si uvědomit, když budu chtít z 2D obrazu promítnout klik do 3D prostoru. Budu to potřebovat na vyznačení určité části prostoru. Zde je vidět kód, který vytvoří vektor se směrem od kamery k promítací rovině.  

\lstinputlisting[language=JavaScript,label={secref:secref7},caption=Projekce myši do 3D prostoru.]{SourceCodes/mouseProjection.js}

Nejprve musím vytvořit událost, abych mohl zjistit pozici kliku. Tato hodnota je vydělena šířkou celého vnitřního okna prohlížeče, to celé vynásobené dvěmi a odečteno jedničkou. Tímto způsobem je vytvořená i \texttt{y} hodnota. Potřebuji, abych ve středu obrazovky měl koordinát (0,0), k tomu tato část kódu slouží. Po této kostrukci budou hodnoty \texttt{x, y} v intervalu $\left\langle-1,1\right\rangle$. Abych mohl vytvořit vektor v prostoru, tak mi nestačí \texttt{x, y}, proto musím vytvořit trojrozměrný vector s nově vypočítanými hodnotami \texttt{x} a \texttt{y}. Jako hodnota osy \texttt{z} bude nula. Hodnota z by na tomto místě pouze určovala posun od středu kamery k plátnu při interních výpočtech. \texttt{THREE.Vector3} má metodu \texttt{unproject} s parametrem typu Camera, vložím zde hlavní perspektivní kameru. Na směrový vektor z obrazovky se aplikuje projekční matice z kamery. Výsledkem se stane vector, který ze středu kamery udá směr odpovídající přímce. Na této přímce jsou všechny body, které odpovídají projekci kliku z obrazovky. Obrázek \ref{fig:perspectiveProjection}  pomůže s lepší představou. Po kliknutí získám pozici na obrazovce, která na obrázku představuje rovinu blíže kameře a bod ležící na ní. Při provedení výše zmíněného kódu získám vektor, který určí směr v trojrozměrném prostoru. Pak už záleží, v jaké vzdálenosti od kamery požadovanou pozici chci.

Selekci musím z dvojrozměrné obrazovky přenést do trojrozměrného prostoru a vizualizovat obrys selekce. Zároveň musí mít obrys všech vyznačených prostorů takovou rotaci, že obrys je natočen kolmo ke středu celého světa. K vytvoření obrysu potřebuji dva body z obrazovky. Pro první bod použiji kód \ref{secref:secref7}, a přidám k němu další část \ref{secref:secref8}.

\lstinputlisting[language=JavaScript,label={secref:secref8},caption=Zvětšení délky vektoru.]{SourceCodes/scalingVector.js}

Nejdříve spočítám délku vektoru, pak vydělím číslo tři délkou vektoru. Číslo tři, protože chci, aby všechny selekce byly v okolí naší pozice maximálně tři jednotky od kamery. Později budu pohybovat mou vyznačenou selekcí okolo mé pozice. Pohybovat jí budu po kouli, která bude hlavní kameru obklopovat. A v posledním kroku vynásobím vektor proměnnou \texttt{scalingFactor}. Tímto zajistím zvětšení vektoru při zachování směru. 

Druhý bod se bude trošku lišit od projekce prvního bodu. 

\lstinputlisting[language=JavaScript,caption=Promítnutí druhého bodu obrysu selekce.]{SourceCodes/secondPoint.js}

Zde poprvé ukáži třídu \texttt{Raycaster}. Tato třída slouží k detekci objektů. Po inicializaci \texttt{Raycasteru} musím namířit na správný směr a nastavit správnou pozici. O to se postará metoda \texttt{setFromCamera} se dvěmi vstupními parametry. Prvním je \texttt{THREE.Vector2}, který obsahuje vypočítané údaje pro projekci bodu a druhým parametrem je hlavní kamera. Nyní si vytvořím rovinu z coplanar bodu a normály. Jako coplanar bod využívám ten, který jsem vytvořil na začátku této podkapitoly. Jako poslední krok řeknu raycasteru, aby vyslal paprsek, který má zkusit protnout rovinu a výsledek uložit do proměnné \texttt{result}.


\begin{minipage}{\linewidth}
\lstinputlisting[language=JavaScript,label={secref:secref9},caption=Vytvoření obrysu selekce.]{SourceCodes/makeBorder.js}  
\end{minipage}

Proměnné \texttt{firstPoint} a \texttt{secondPoint} odpovídají získaným bodům z této podkapitoly. Z těchto trojrozměrných vektorů musím zjistit délku \texttt{x} a \texttt{y} vytvářeného obdelníku. Tyto vzdálenosti jsou důležité při vytváření obrysového obdelníku. 

\lstinputlisting[language=JavaScript,caption=Použití THREE.Shape k vytvoření obdelníku.]{SourceCodes/create3DLine.js} 

V tomto kódu vytvářím vlastní tvar. Postupně, díky délkám stran obdelníku, vytvářím obdelník s pomocí \texttt{THREE.Shape}. Tuto třídu používám z důvodu jednoduchého rozhraní pro vytvoření geometrie objektu v dvojrozměrném prostoru, která je jednoduše přenesitelná do trojrozměrného prostoru. Po vytvoření obdelníkového tvaru z něj získám geometrii, a s pomocí materiálu vytvořím nový objekt typu \texttt{THREE.Line}. Tomuto vrácenému objektu musím nastavit pozici, protože všechny objekty mají výchozí pozici ve středu scény. Na nový tvar musím ještě aplikovat rotaci podle rotace světa. Důvodem, proč musím aplikovat rotaci je, že tvar byl vytvořen v dvojrozměrném prostoru a přenesen do trojrozměrného, proto když nový tvar přidám do scény, tak bude vodorovně s osou \texttt{x}, \texttt{y}, ale kolmo na osu \texttt{z} ve všech případech. Nakonec si ještě přidám do objektu pomocné informace pro budoucí použití a přidám do skupiny obrysů.

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{Figures/selectionBeforeProjection.png}
\caption{První bod a druhý bod selekce. }
\label{fig:selectionBefore}
\end{figure} 

\begin{figure}[H]
\centering
\includegraphics[width=\linewidth]{Figures/selectionAfterProjection.png}
\caption{Promítnutí bodů s již vytvořeným obrysem. }
\label{fig:selectionAfter}
\end{figure}

Zmíněné ukázky kódu nevytvářejí oranžový obrys \ref{fig:selectionBefore} na obrazovce. Již promítnutá selekce v prostoru \ref{fig:selectionAfter} je výsledkem ze zmíněných ukázek kódu v kapitole \ref{secref:secref10}. Obrys \ref{fig:selectionBefore} nakreslený s pomocí canvas elementu na 2D obrazovce vypadá naprosto identicky, jako obrys v prostoru \ref{fig:selectionAfter} díky projekci.


\subsection{Zachycení obrazu selekce}\label{secref:secref13} 
V kapitole \ref{secref:secref16} jsem vysvětlil základní princip perspektivní projekce, teď ukáži, jakým způsobem je prováděna. K provedení projekce potřebuji projekční matici. Každá kamera má projekční matici. Tato projekční matice 4x4 je vytvořena při vytvoření kamery. Nejdříve vysvětlím na základě jakých parametrů je perspektivní projekční matice vytvořena, poté ukáži výsledný tvar objektu po aplikování a nakonec implementaci zachycení obrazů selekcí. 

\begin{equation}
		P =
		\begin{bmatrix}%
    x & 0 & 0 & 0 \\
		0 & y & 0 & 0 \\ 
		0 & 0 & a & b \\
		0 & 0 & -1 & 0 
    \end{bmatrix}
\label{eq:eq4}
\end{equation}


Zjednodušený vzorec projekční matice kamery, kterou používá knihovna Three.js. Při vytváření nové kamery \ref{secr:additionalcamera} jsem specifikoval ještě další údaje. Tyto údaje jsou horizontální \texttt{FOV} ve stupních, poměr stran a vzdálenost přední a zadní roviny kamerového frustumu. Všechny tyto informace budu potřebovat na vytvoření projekční matice. 

$$y = \frac{1}{\tan(\frac{FOV}{2} * \frac{\pi}{180})}$$ 

Tímto vzorcem vypočítám délku odvěsny uvnitř kamerového frustumu. Používám funkci tangens s polovinou úhlu FOV, násobenou $\frac{\pi}{180}$ pro převod ze stupňů na radiány. Používám pouze polovinu úhlu FOV, protože mě zajímá pravý úhel uvnitř frustumu. 

$$x = \frac{y}{aspect}$$ 

Pro získání této hodnoty využiji výsledek předešlé rovnice a vydělím ji poměrem stran. Tento poměr stran jsem získal při vytváření kamerového objektu. Tímto jsem upravil kamerové frustum tak, aby se nepodobalo pravidelnému rovnostrannému hranolu. Teď přední rovina kamerového frustumu již není čtverec, ale obdélník. Tyto dva parametry matice budou ovlivňovat hodnoty \texttt{x,y} v naší projekci. Hodnoty \texttt{a,b} budou ovlivňovat změnu měřítka objektu na vzdálenosti od pozice kamery. 

$$a = \frac{-\left(f+n\right)}{f-n}$$ 
$$b = \frac{-2fn}{f-n}$$ 

Výsledek hodnoty $a$ bude měnit měřítko souřadnice \texttt{z} v kartézské soustavě souřadnic, a hodnota $b$ bude konstanta, která bude přičtena k výsledné souřadnici \texttt{z}. Proměnná $f$ značí vzdálenost od pozice kamery po nejvzdálenější rovinu kamerového frustumu. Tuto vzdálenost jsem vkládal při vytváření kamerového objektu. Proměnná $n$ označuje vzdálenost k nejbližší rovině kamerového frustumu. 

Ukáži, co se stane s objekty po aplikování projekční matice. Na obrázcích \ref{fig:projectionMatrixCameraFrustum1} a \ref{fig:projectionMatrixCameraFrustum2} jsou modře zbarvené objekty uvnitř červeného kamerového frustumu. Červeně vyznačená část je jediná část scény, která je viditelná. Pokud vše vynásobím projekční maticí, získám \ref{fig:projectionMatrixCameraFrustum2}. Nyní se z frustumu stal kvádr a všechny objekty byly také transformovány. Objekty, které jsou blíže kameře, jsou větší, a s rostoucí vzdáleností se objekty stávají menšími, stejně jako v reálném životě. Na obrázku \ref{fig:finalProjectionImageFromCamera} vidíme vykreslení finálního výsledku. 

\begin{figure}[H]
    \centering
    \begin{minipage}[c]{0.48\linewidth}        %% or \columnwidth
        \centering
        \includegraphics[width=\linewidth]{Figures/projectionMatrixCameraFrustum1.png}
        \caption{Ukázka kamerového frustumu před projekcí \cite{tutorial3matrices}.} % todo add citation http://www.opengl-tutorial.org/beginners-tutorials/tutorial-3-matrices/}
        \label{fig:projectionMatrixCameraFrustum1}
    \end{minipage}
    \begin{minipage}[c]{0.48\linewidth}        %% or \columnwidth
        \centering
        \includegraphics[width=\linewidth]{Figures/projectionMatrixCameraFrustum2.png}
        \caption{Ukázka kamerového frustumu po projekci \cite{tutorial3matrices}.}
        \label{fig:projectionMatrixCameraFrustum2}
    \end{minipage}
\end{figure}


\begin{figure}[H]
\centering
\includegraphics[width=0.6\linewidth]{Figures/finalProjectionImageFromCamera.png}
\caption{Výsledný obraz po projekci \cite{tutorial3matrices}. }
\label{fig:finalProjectionImageFromCamera}
\end{figure} 

K implementaci zachycení obrazu selekce budu potřebovat novou kameru, která bude směřovat na střed naší selekce. Kamery potřebuji k vytvoření nových projekcí. Vytvořím novou perspektivní kameru a namířím ji na střed mezi dvěma námi vytvořenými body v podkapitole \ref{secref:secref10} 

\lstinputlisting[language=JavaScript,label={secr:additionalcamera},caption=Vytváření kamery pro sledování selekce.]{SourceCodes/additionalCamera.js}
 
Tento kód vytvoří novou perspektivní kameru a nastaví ji pozici ve středu scény. Dále ji nastavíme směr, na který se bude dívat. Vektoru s požadovaným směrem docílím tak, že sečtu vektor prvního a druhého bodu. Výsledkem je vektor procházející středem mezi těmito body. Nakonec přidám tuto kameru do skupiny pomocných kamer. 

\lstinputlisting[language=JavaScript,caption=Získání snímku z kamery.]{SourceCodes/createImageFromCameras.js}


\subsection{Export vybraných bodů z selekce}
Pro získání bodů v označené selekci musím vzít na vědomí, že používám perspektivní kameru a na monitoru vidím projekci. Tím pádem obsah selekce bude připomínat jehlan, který má hlavní vrchol ve středu kamery a každá hrana obrysu leží na rovině procházející pozicí kamery. Roviny rozdělí prostor na požadovanou selekci. Tento prostor obsahuje všechny chtěné LIDARové body. Nejdříve musím vytvořit zmíněné roviny, abych ohraničil prostor selekce. U selekce znám střední bod a délky stran. Pro vytvoření roviny jsou potřeba tři body neležící na jedné přímce. Jeden bod bude společný u všech rovin, a tím bude pozice hlavní kamery. Další dva body budou vždy vrcholy hrany selekce. Problém je, že znám pouze jeden bod, který není ovlivněn rotací. U zbylých bodů budu muset vypočítat pozici po provedené rotaci. Obrys, který nemá žádnou rotaci, je vodorovný s osou \texttt{x}. 


\lstinputlisting[language=JavaScript,caption=Získání pozice vrcholu obrysu po provedení rotace.]{SourceCodes/rotateVectorAndReturnPosition.js} 


V ukázce chci získat pravý spodní bod obrysu. Vím, že pozice obrysu je vždy ve středu. Abych získal pravý spodní bod, tak musím posunout středový bod selekce do středu scény a zrušit rotaci. Nyní na základě vzdálenosti \texttt{x} a \texttt{y} našeho obrysu vytvořím vektor směřující k pravému dolnímu rohu obrysu bez rotace a s pozicí ve středu scény. Na tento vektor použiji stejnou rotaci, jako má selekci. Na rotaci se použijí transformační matice \eqref{eq:eq1}, \eqref{eq:eq2}, \eqref{eq:eq3} \cite{sojka_2003}.

\begin{equation}
		A_x =
		\begin{bmatrix}%
    1 & 0 & 0 \\
		0 & \cos \alpha & -\sin \alpha \\ 
		0 & \sin \alpha & \cos \alpha
    \end{bmatrix}
\label{eq:eq1}
\end{equation}

\begin{equation}
		A_y =
		\begin{bmatrix}%
    \cos \beta & 0 & \sin \beta \\
		0 & 1 & 0 \\ 
		-\sin \beta & 0 & \cos \beta
    \end{bmatrix}
\label{eq:eq2}
\end{equation}

\begin{equation}
		A_z =
		\begin{bmatrix}%
    \cos \gamma & -\sin \gamma & 0 \\
		\sin \gamma & \cos \gamma & 0 \\ 
		0 & 0 & 1
    \end{bmatrix}
\label{eq:eq3}
\end{equation}

Obrys má rotaci uloženou ve vlastnostech \texttt{x,y,z}, a každá z nich popisuje, o kolik radiánů se má otočit kolem stejnojmenné osy. Při zavolání metody \texttt{applyEuler()} na proměnné \texttt{vector} se tento vektor vynásobí maticí \eqref{eq:eq1}, kde $ \alpha = \texttt{line.rotation.x} $. Stejný postup se provede u \texttt{y} a \texttt{z}.  

Když mám všechny potřebné body po transformaci, tak vytvořím roviny jehlanu. Musím zajistit, aby normály všech rovin směřovaly do ohraničeného prostoru. 

\lstinputlisting[language=JavaScript,caption=Získání všech bodů v selekci.]{SourceCodes/CustomFrustum.js} 

Třída \texttt{CustomFrustum} slouží pro uložení našeho jehlanu. Při sběru bodů selekce musím v cyklu proiterovat všechny LIDARové body a zjistit, jestli uvnitř jehlanu. Zjišťuji, jestli vzdálenost od všech rovin je kladné číslo. Pokud ne, tak vím, že bod leží mimo náš jehlan. Další, co si ke všem LIDARovým bodům uložím, je obrys selekce z důvodu opětovného přehrání dat ze selekcí.



\subsection{Pohyb selekcí} 
Než začnu, tak musím vzít v úvahu, že obrysy jsou v prostoru scény a já vidím jejich projekci. Takže budu muset zjistit s pomocí projekce na zadní rovinu frustumu kamery, jestli nějaký obrys byl protnut při této akci. Když zjistím, že obrys byl zasáhnut, tak musím získat všechny potřebné údaje pro budoucí práci s ním. Musel jsem se rozhodnout, jakým způsobem chci, aby se obrys selekce pohyboval v trojrozměrném prostoru, a jakým způsobem budu ovládat pohyb z dvojrozměrné obrazovky. Rozhodl jsem se, že obrysy musí být pohybovatelné okolo kamery, a proto pohyb selekce musí kopírovat poloměr koule. Rotace obrysu bude záviset na hlavní kameře, ze které budu pohyb ovládat.

\medskip
\begin{minipage}{\linewidth}
\lstinputlisting[language=JavaScript,label={secref:secref11},caption=Získání obrysu na základě události myši.]{SourceCodes/onMouseClickDrag.js} 
\end{minipage}

Budu potřebovat vytvořit události na adekvátní akce myši. K tomu budu potřebovat použít \texttt{THREE.Raycaster}, který pomocí bodu z mé obrazovky zjistí, zda nějaký objekt je ve scéně za touto projekcí. Nejdříve nastavím \texttt{raycaster}, aby použil projekční matici hlavní perspektivní kamery, pak použiji metodu \texttt{intersectObjects} s parametrem \texttt{objects}. Ten obsahuje všechny obrysy selekce. Pokud nějaký obrys našel, tak si objekt uložím do třídní proměnné \texttt{selected}. Kdyby bylo více obrysů za sebou, metoda by vrátila oba obrysy, ale seřadila by je od nejbližšího po nejvzdálenější. Proměnnou \texttt{selected} použiji i při dalších událostech, pak pomocí metody \texttt{intersectSphere} získám pozici střetu koule, po které chci obrys pohybovat s projekčním paprskem. Výsledek je pak uložen do proměnné \texttt{intersection}. Obrys má pouze jediný pevný bod, na který se nevztahuje rotace, a ten je uložen ve vlastnosti \texttt{position}. Od tohoto bodu je vytvořená geometrie, která podléhá rotaci. Když budu vybírat obrys v naší scéně, tak nebudu vždy mířit na tento bod, proto potřebuje odchylku kliknutí od pevného bodu. To mi zařizuje proměnná \texttt{offset}, která zkopíruje bod dotyku s koulí a odečte z něj pozici pevného bodu obrysu. Výsledkem bude vektor, který při pohybu budu muset odčítat, abych mohl z jakéhokoliv místa pohybovat obrysem a zachoval pohyb po chtěné kouli. Kód \ref{secref:secref11} přiřadím k události \texttt{mousedown}.

\lstinputlisting[language=JavaScript,label={secref:secref12},caption=Pohyb obrysu ve scéně.]{SourceCodes/onMouseMoveDrag.js}

Do proměnné \texttt{rect} získám velikost scény v prohlížeči a nastavím \texttt{raycaster}, aby směřoval na pozici v prostoru, kterou jsem získal projekcí aktuální pozice z obrazovky. Stejně jako v předchozím příkladu použiji proměnnou \texttt{intersection} pro získání pozice střetu s koulí po projekci kurzoru na kouli, a nastavím délku tohoto vektoru na poloměr koule. Nakonec nastavím obrysu rotaci na základě kamery, aby obrys měl rotaci proti kameře. Tento kód \ref{secref:secref12} přiřadím k události \texttt{mousemove}.    

\lstinputlisting[language=JavaScript,label={secref:secref14},caption=Zrušení pohybu a zaměření kamery pro zasílání obrázových dat.]{SourceCodes/onMouseCancelDrag.js}

Při událostech typu \texttt{mouseup, mouseleave} musím natočit kameru, s kterou zachycuji obrazová data selekcí \ref{secref:secref13}. Musím zjistit bod ve středu obrysu, na který byla použita rotační transformace. K tomu vytvořím vektor, který bude popisovat směr ke středu obrysu bez rotace. Nasledně na tento vektor aplikuji kompletní rotaci stejnou jako je na obrysu selekce a přičtu k němu pevný bod selekce. Tímto způsobem jsem získal pozici středu obrysu a nyní jen kameru sledující selekci nastavím, aby sledovala tuto pozici pomocí metody \texttt{lookAt}. Nakonec uvolním proměnnou \texttt{selected}. Tyto části kódu zařídí, že selekce bude pohybovatelná okolo naší kamery při zachování dosavadní funkcionality systému.


\section{Závěr}
Cílem bakalářské práce bylo nastudovat potřebné webové knihovny pro vytvoření vizualizačního nástroje LIDARových dat s podporou selekcí obrazových i datových částí. Součástí bylo také nastudování principu LIDARu, ukládání a formát jeho dat. Tato část byla nutná k vizualizování LIDARových dat.

V rámci této práce byla vytvořena vizualizace LIDARových dat ve webovém prohlížeči s podporou selekcí části prostoru. Selekce jsou na základě akcí upravovatelné. Export LIDARových bodů selekce na server plus obrazová data pozadí těchto bodů. Znovupřehrání selekcí i s obsaženými daty také zaimplementováno.

Tato práce mi byla velkým přínosem. Rozšířila mi obzory, a díky ní jsem získal obecný přehled ohledně počítačové grafiky, vizualizačních algoritmů a nepostradatelnou součást matematiky. Délka implementace systému se velmi lišila od mých odhadů z důvodu neznalosti základů geometrie, projekcí kamer, transformačních matic a nulových zkušeností s WebGl. I s brzkým začátkem implementační části projektu se z již zmíněných důvodů produktivní vývoj blížil až ke konci projektu.
 
%\addcontentsline{toc}{section}{Závěr}

\newpage
\nocite{*}
\renewcommand\refname{Literatura}
%\section*{Literatura}
\addcontentsline{toc}{section}{Literatura}

%\bibliography{mybib}
%\bibliographystyle{plain}
\printbibliography
%\bibliography{mybib}


%add to citation https://developer.okta.com/blog/2019/07/19/mysql-vs-postgres


% https://en.wikipedia.org/wiki/OpenGL
% https://en.wikipedia.org/wiki/JavaScript
% https://en.wikipedia.org/wiki/List_of_WebGL_frameworks
% https://en.wikipedia.org/wiki/WebGL
% https://cs.wikipedia.org/wiki/JavaScript
% https://en.wikipedia.org/wiki/Point_cloud
% 	
%		
%https://aframe.io/docs/0.9.0/introduction/html-and-primitives.html#sidebar
%
%https://www.scratchapixel.com/lessons/3d-basic-rendering/rendering-3d-scene-overview/visibility-problem
\end{document}